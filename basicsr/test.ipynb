{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "from os import path as osp\n",
    "import os\n",
    "\n",
    "from basicsr.data import create_dataloader, create_dataset\n",
    "from basicsr.data.data_sampler import EnlargedSampler\n",
    "from basicsr.data.prefetch_dataloader import CPUPrefetcher, CUDAPrefetcher\n",
    "from basicsr.models import create_model\n",
    "from basicsr.utils import (MessageLogger, check_resume, get_env_info,\n",
    "                           get_root_logger, get_time_str, init_tb_logger,\n",
    "                           init_wandb_logger, make_exp_dirs, mkdir_and_rename,\n",
    "                           set_random_seed)\n",
    "from basicsr.utils.dist_util import get_dist_info, init_dist\n",
    "from basicsr.utils.options import dict2str, parse\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable distributed.\n"
     ]
    }
   ],
   "source": [
    "def parse_options(is_train=True):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '-opt', type=str, default='../options/train/NAFSSR/NAFSSR-T_x4.yml', help='Path to option YAML file.')\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "\n",
    "    parser.add_argument('--input_path', type=str, required=False, help='The path to the input image. For single image inference only.')\n",
    "    parser.add_argument('--output_path', type=str, required=False, help='The path to the output image. For single image inference only.')\n",
    "    parser.add_argument('--f', required=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    opt = parse(args.opt, is_train=is_train)\n",
    "\n",
    "    # distributed settings\n",
    "    if args.launcher == 'none':\n",
    "        opt['dist'] = False\n",
    "        print('Disable distributed.', flush=True)\n",
    "    else:\n",
    "        opt['dist'] = True\n",
    "        if args.launcher == 'slurm' and 'dist_params' in opt:\n",
    "            init_dist(args.launcher, **opt['dist_params'])\n",
    "        else:\n",
    "            init_dist(args.launcher)\n",
    "            print('init dist .. ', args.launcher)\n",
    "\n",
    "    opt['rank'], opt['world_size'] = get_dist_info()\n",
    "\n",
    "    # random seed\n",
    "    seed = opt.get('manual_seed')\n",
    "    if seed is None:\n",
    "        seed = random.randint(1, 10000)\n",
    "        opt['manual_seed'] = seed\n",
    "    set_random_seed(seed + opt['rank'])\n",
    "\n",
    "    if args.input_path is not None and args.output_path is not None:\n",
    "        opt['img_path'] = {\n",
    "            'input_img': args.input_path,\n",
    "            'output_img': args.output_path\n",
    "        }\n",
    "    opt['path']['models'] = '../test_results'\n",
    "    return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network(self, net, net_label, current_iter, param_key='params'):\n",
    "    \"\"\"Save networks.\n",
    "\n",
    "    Args:\n",
    "        net (nn.Module | list[nn.Module]): Network(s) to be saved.\n",
    "        net_label (str): Network label.\n",
    "        current_iter (int): Current iter number.\n",
    "        param_key (str | list[str]): The parameter key(s) to save network.\n",
    "            Default: 'params'.\n",
    "    \"\"\"\n",
    "    if current_iter == -1:\n",
    "        current_iter = 'latest'\n",
    "    save_filename = f'{net_label}_{current_iter}.pth'\n",
    "    save_path = os.path.join(self.opt['path']['models'], save_filename)\n",
    "\n",
    "    net = net if isinstance(net, list) else [net]\n",
    "    param_key = param_key if isinstance(param_key, list) else [param_key]\n",
    "    assert len(net) == len(\n",
    "        param_key), 'The lengths of net and param_key should be the same.'\n",
    "\n",
    "    save_dict = {}\n",
    "    for net_, param_key_ in zip(net, param_key):\n",
    "        net_ = self.get_bare_model(net_)\n",
    "        state_dict = net_.state_dict()\n",
    "        for key, param in state_dict.items():\n",
    "            if key.startswith('module.'):  # remove unnecessary 'module.'\n",
    "                key = key[7:]\n",
    "            state_dict[key] = param.cpu().to(torch.float16)\n",
    "            # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ converted float32 to float16\n",
    "        save_dict[param_key_] = state_dict\n",
    "\n",
    "    torch.save(save_dict, save_path)\n",
    "\n",
    "def load_network(self, net, load_path, strict=True, param_key='params'):\n",
    "    \"\"\"Load network.\n",
    "\n",
    "    Args:\n",
    "        load_path (str): The path of networks to be loaded.\n",
    "        net (nn.Module): Network.\n",
    "        strict (bool): Whether strictly loaded.\n",
    "        param_key (str): The parameter key of loaded network. If set to\n",
    "            None, use the root 'path'.\n",
    "            Default: 'params'.\n",
    "    \"\"\"\n",
    "    net = self.get_bare_model(net)\n",
    "    load_net = torch.load(\n",
    "        load_path, map_location=lambda storage, loc: storage)\n",
    "    if param_key is not None:\n",
    "        load_net = load_net[param_key]\n",
    "    print(' load net keys', load_net.keys)\n",
    "    # remove unnecessary 'module.'\n",
    "    for k, v in deepcopy(load_net).items():\n",
    "        # v = v.to(torch.int8)\n",
    "        if k.startswith('module.'):\n",
    "            load_net[k[7:]] = v\n",
    "            load_net.pop(k)\n",
    "        # print(v.dtype)\n",
    "    self._print_different_keys_loading(net, load_net, strict)\n",
    "    net.load_state_dict(load_net, strict=strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 11:05:34,648 INFO: Model [ImageRestorationModel] is created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. cosineannealingLR\n"
     ]
    }
   ],
   "source": [
    "opt = parse_options(is_train=True)\n",
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_network(model, model.net_g, 'net_g', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " load net keys <built-in method keys of collections.OrderedDict object at 0x7fa83d51c440>\n"
     ]
    }
   ],
   "source": [
    "load_network(model, model.net_g, '../test_results/net_g_latest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "model = torch.load('model.pt')\n",
    "\n",
    "# Open a file in binary write mode\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    # Serialize the model to the file\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Close the file\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
